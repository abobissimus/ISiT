{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6aebe0-7829-4456-be23-8104d9abf2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ 5 —Ü–µ–ª—ã—Ö –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª (–æ–±—ä—ë–º—ã –≤ –º–ª):  10 10 10 10 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74966caef71d450c995c4958af77f1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: [10 10 10 10 15]\n",
      "–û–±—â–∏–π –æ–±—ä—ë–º: 55 –º–ª\n",
      "–ú–∞–∫—Å. –≤ —Å—Ç–∞–∫–∞–Ω–µ: 15 –º–ª ‚Üí —à–∞–≥ –ø–µ—Ä–µ–ª–∏–≤–∞–Ω–∏—è: 1 –º–ª\n",
      "–¶–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: [11, 11, 11, 11, 11]\n",
      "\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–µ–¥—ã...\n",
      "\n",
      "üß† –û–±—É—á–µ–Ω–∏–µ DQN-–∞–≥–µ–Ω—Ç–∞...\n",
      "–ß–∏—Å–ª–æ –¥–µ–π—Å—Ç–≤–∏–π: 1125\n",
      "–û–±—â–µ–µ —á–∏—Å–ª–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è: 150000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'reward_plot.html'\n",
      "\n",
      "üß™ –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞:\n",
      "–ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: [10 10 10 10 15] –º–ª\n",
      "–®–∞–≥ 1: –∏–∑ 4 ‚Üí –≤ (1, 2, 3), –æ–±—ä—ë–º 4 –º–ª ‚Üí [10 12 11 11 11] –º–ª\n",
      "–®–∞–≥ 2: –∏–∑ 1 ‚Üí –≤ (0, 3, 4), –æ–±—ä—ë–º 1 –º–ª ‚Üí [11 11 11 11 11] –º–ª\n",
      "‚úÖ –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞!\n",
      "\n",
      "–§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: [11 11 11 11 11] –º–ª\n",
      "–¶–µ–ª—å: [11, 11, 11, 11, 11] –º–ª\n",
      "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import itertools\n",
    "import torch as th\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import matplotlib\n",
    "\n",
    "# =======================================\n",
    "# –í–≤–æ–¥ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "# =======================================\n",
    "def get_initial_state():\n",
    "    while True:\n",
    "        try:\n",
    "            inp = input(\"–í–≤–µ–¥–∏—Ç–µ 5 —Ü–µ–ª—ã—Ö –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª (–æ–±—ä—ë–º—ã –≤ –º–ª): \")\n",
    "            volumes = list(map(int, inp.split()))\n",
    "            if len(volumes) != 5:\n",
    "                print(\"–ù—É–∂–Ω–æ —Ä–æ–≤–Ω–æ 5 —á–∏—Å–µ–ª!\")\n",
    "                continue\n",
    "            if any(v < 0 for v in volumes):\n",
    "                print(\"–û–±—ä—ë–º—ã –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏!\")\n",
    "                continue\n",
    "            if sum(volumes) == 0:\n",
    "                print(\"–û–±—â–∏–π –æ–±—ä—ë–º –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω—É–ª–µ–≤—ã–º!\")\n",
    "                continue\n",
    "            arr = np.array(volumes, dtype=np.int32)\n",
    "            if arr.max() > 500:\n",
    "                print(\"–û–±—ä—ë–º –≤ –æ–¥–Ω–æ–º —Å—Ç–∞–∫–∞–Ω–µ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 500 –º–ª.\")\n",
    "                continue\n",
    "            if arr.sum() > 2500:\n",
    "                print(\"–°—É–º–º–∞—Ä–Ω—ã–π –æ–±—ä—ë–º –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 2500 –º–ª.\")\n",
    "                continue\n",
    "            return arr\n",
    "        except ValueError:\n",
    "            print(\"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–≤–æ–¥. –ü—Ä–∏–º–µ—Ä: 200 0 0 0 0\")\n",
    "\n",
    "# =======================================\n",
    "# –í—ã–±–æ—Ä —à–∞–≥–∞ –ø–µ—Ä–µ–ª–∏–≤–∞–Ω–∏—è\n",
    "# =======================================\n",
    "def get_volume_step(max_vol):\n",
    "    if max_vol <= 50:\n",
    "        return 1\n",
    "    elif max_vol <= 100:\n",
    "        return 2\n",
    "    elif max_vol <= 200:\n",
    "        return 5\n",
    "    elif max_vol <= 500:\n",
    "        return 10\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "# =======================================\n",
    "# –°—Ä–µ–¥–∞\n",
    "# =======================================\n",
    "class CompoteEnv(gym.Env):\n",
    "    def __init__(self, initial_state: np.ndarray, max_steps=100, volume_step=10, max_volume=500):\n",
    "        super().__init__()\n",
    "        self.n_glasses = 5\n",
    "        self._initial_state_frozen = initial_state.copy()\n",
    "        self.total_volume = int(self._initial_state_frozen.sum())\n",
    "        self.max_steps = max_steps\n",
    "        self.volume_step = volume_step\n",
    "        self.max_volume = max_volume\n",
    "\n",
    "        # –¶–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–∫–∞–∫ Python int, –Ω–µ np.int64)\n",
    "        base = self.total_volume // self.n_glasses\n",
    "        rem = self.total_volume % self.n_glasses\n",
    "        self.target = [int(base + 1)] * rem + [int(base)] * (self.n_glasses - rem)\n",
    "\n",
    "        # –ù–∞–±–ª—é–¥–µ–Ω–∏–µ\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=self.max_volume, shape=(5,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä—ë–º –¥–ª—è –ø–µ—Ä–µ–ª–∏–≤–∞–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ —Ç–æ—Ç, —á—Ç–æ –±—ã–ª –≤ –Ω–∞—á–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏\n",
    "        self.max_possible_pour = int(self._initial_state_frozen.max())\n",
    "\n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏–π: (–∏—Å—Ç–æ—á–Ω–∏–∫, (—Ü–µ–ª–∏,), –æ–±—ä—ë–º)\n",
    "        self._actions = []\n",
    "        for src in range(5):\n",
    "            others = [i for i in range(5) if i != src]\n",
    "            for r in range(1, len(others) + 1):\n",
    "                for subset in itertools.combinations(others, r):\n",
    "                    vol = self.volume_step\n",
    "                    while vol <= self.max_possible_pour:\n",
    "                        self._actions.append((src, subset, vol))\n",
    "                        vol += self.volume_step\n",
    "        self.action_space = spaces.Discrete(len(self._actions))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.state = self._initial_state_frozen.copy().astype(np.float32)\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º prev_deviation —Ç–µ–∫—É—â–∏–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º\n",
    "        initial_dev = np.abs(np.sort(self._initial_state_frozen) - np.sort(self.target)).sum()\n",
    "        self.prev_deviation = float(initial_dev)\n",
    "        self.steps = 0\n",
    "        return self.state, {}\n",
    "\n",
    "    def _is_balanced(self, state):\n",
    "        return sorted([int(x) for x in state]) == sorted(self.target)\n",
    "\n",
    "    def step(self, action_idx):\n",
    "        self.steps += 1\n",
    "        action = self._actions[action_idx]\n",
    "\n",
    "        src, targets, volume_to_pour = action\n",
    "        available = self.state[src]\n",
    "\n",
    "        if volume_to_pour > available or volume_to_pour <= 0:\n",
    "            done = self._is_balanced(self.state)\n",
    "            truncated = self.steps >= self.max_steps\n",
    "            reward = -100.0\n",
    "            return self.state.copy(), reward, done, truncated, {}\n",
    "\n",
    "        self.state[src] -= volume_to_pour\n",
    "        n = len(targets)\n",
    "        per_target = volume_to_pour // n\n",
    "        remainder = int(volume_to_pour - per_target * n)\n",
    "\n",
    "        for i, t in enumerate(targets):\n",
    "            self.state[t] += per_target\n",
    "            if i < remainder:\n",
    "                self.state[t] += 1\n",
    "\n",
    "        self.state = np.clip(self.state, 0, self.max_volume)\n",
    "\n",
    "        done = self._is_balanced(self.state)\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        # === –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–ê–ì–†–ê–î–ê ===\n",
    "        curr_dev = np.abs(np.sort(self.state) - np.sort(self.target)).sum()\n",
    "        if done:\n",
    "            reward = 200.0\n",
    "        else:\n",
    "            improvement = self.prev_deviation - curr_dev\n",
    "            reward = improvement * 0.5 - 1.0\n",
    "        self.prev_deviation = curr_dev\n",
    "        return self.state.copy(), reward, done, truncated, {}\n",
    "\n",
    "# =======================================\n",
    "# Callback –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "# =======================================\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, eval_env, eval_freq=1000, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.eval_env = eval_env\n",
    "        self.eval_freq = eval_freq\n",
    "        self.rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps % self.eval_freq == 0:\n",
    "            obs, _ = self.eval_env.reset()\n",
    "            episode_reward = 0.0\n",
    "            steps = 0\n",
    "            while steps < 100:\n",
    "                action, _ = self.model.predict(obs, deterministic=False)\n",
    "                obs, r, d, tr, _ = self.eval_env.step(action)\n",
    "                episode_reward += r\n",
    "                steps += 1\n",
    "                if d or tr:\n",
    "                    break\n",
    "            self.rewards.append(episode_reward)\n",
    "        return True\n",
    "\n",
    "# =======================================\n",
    "# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\n",
    "# =======================================\n",
    "def main():\n",
    "    initial = get_initial_state()\n",
    "    total_vol = initial.sum()\n",
    "    max_in_st = initial.max()\n",
    "    volume_step = get_volume_step(max_in_st)\n",
    "\n",
    "    print(f\"\\n–ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {initial}\")\n",
    "    print(f\"–û–±—â–∏–π –æ–±—ä—ë–º: {total_vol} –º–ª\")\n",
    "    print(f\"–ú–∞–∫—Å. –≤ —Å—Ç–∞–∫–∞–Ω–µ: {max_in_st} –º–ª ‚Üí —à–∞–≥ –ø–µ—Ä–µ–ª–∏–≤–∞–Ω–∏—è: {volume_step} –º–ª\")\n",
    "\n",
    "    base = total_vol // 5\n",
    "    rem = total_vol % 5\n",
    "    target = [int(base + 1)] * rem + [int(base)] * (5 - rem)\n",
    "    print(f\"–¶–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {sorted(target, reverse=True)}\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –¥–≤–µ –ù–ï–ó–ê–í–ò–°–ò–ú–´–ï —Å—Ä–µ–¥—ã\n",
    "    env = CompoteEnv(initial, max_steps=100, volume_step=volume_step, max_volume=500)\n",
    "    eval_env = CompoteEnv(initial, max_steps=100, volume_step=volume_step, max_volume=500)\n",
    "\n",
    "    print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–µ–¥—ã...\")\n",
    "    check_env(env, warn=True)\n",
    "\n",
    "    print(\"\\nüß† –û–±—É—á–µ–Ω–∏–µ DQN-–∞–≥–µ–Ω—Ç–∞...\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "    n_actions = env.action_space.n\n",
    "    print(f\"–ß–∏—Å–ª–æ –¥–µ–π—Å—Ç–≤–∏–π: {n_actions}\")\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        buffer_size=min(20000, n_actions * 10),\n",
    "        learning_starts=3000,\n",
    "        batch_size=64,\n",
    "        gamma=0.99,\n",
    "        exploration_initial_eps=1.0,\n",
    "        exploration_final_eps=0.001,\n",
    "        exploration_fraction=0.3,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=1000,\n",
    "        verbose=0,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    total_timesteps = min(150000, n_actions * 200)\n",
    "    print(f\"–û–±—â–µ–µ —á–∏—Å–ª–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {total_timesteps}\")\n",
    "\n",
    "    reward_logger = RewardLoggerCallback(eval_env, eval_freq=1000)\n",
    "    model.learn(total_timesteps=total_timesteps, callback=reward_logger, progress_bar=True)\n",
    "\n",
    "    # === PLOTLY (offline) ===\n",
    "    rewards = reward_logger.rewards\n",
    "    if rewards:\n",
    "        clean_rewards = [float(r) for r in rewards if np.isfinite(r)]\n",
    "        if clean_rewards:\n",
    "            import plotly.graph_objects as go\n",
    "            x_vals = list(range(1000, 1000 * len(clean_rewards) + 1, 1000))\n",
    "            fig = go.Figure(data=go.Scatter(x=x_vals, y=clean_rewards, mode='lines+markers'))\n",
    "            fig.update_layout(\n",
    "                title=\"–ù–∞–≥—Ä–∞–¥–∞ –∞–≥–µ–Ω—Ç–∞\",\n",
    "                xaxis_title=\"–®–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è\",\n",
    "                yaxis_title=\"–°—É–º–º–∞—Ä–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞\"\n",
    "            )\n",
    "            fig.write_html(\"reward_plot.html\")\n",
    "            print(\"\\n‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ 'reward_plot.html'\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è –ù–µ—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞.\")\n",
    "\n",
    "    # === –¢–ï–°–¢ –ù–ê –û–¢–î–ï–õ–¨–ù–û–ô –°–†–ï–î–ï ===\n",
    "    print(\"\\nüß™ –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞:\")\n",
    "    obs, _ = eval_env.reset()  # ‚Üê –í–ê–ñ–ù–û: eval_env, –Ω–µ env!\n",
    "    print(f\"–ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {obs.astype(int)} –º–ª\")\n",
    "    done, truncated = False, False\n",
    "    step = 0\n",
    "    while not (done or truncated) and step < 100:\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, truncated, _ = eval_env.step(action)  # ‚Üê eval_env!\n",
    "        action_desc = eval_env._actions[action]\n",
    "        step += 1\n",
    "        src, tgts, vol = action_desc\n",
    "        print(f\"–®–∞–≥ {step}: –∏–∑ {src} ‚Üí –≤ {tgts}, –æ–±—ä—ë–º {vol} –º–ª ‚Üí {obs.astype(int)} –º–ª\")\n",
    "        if done:\n",
    "            print(\"‚úÖ –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞!\")\n",
    "        elif truncated:\n",
    "            print(\"‚è±Ô∏è –õ–∏–º–∏—Ç —à–∞–≥–æ–≤ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç.\")\n",
    "\n",
    "    final_state = obs.astype(int)\n",
    "    print(f\"\\n–§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {final_state} –º–ª\")\n",
    "    print(f\"–¶–µ–ª—å: {sorted(target)} –º–ª\")\n",
    "    print(f\"–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ: {sorted(final_state.tolist()) == sorted(target)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1478dc8-80c6-4f9a-81ea-0cf9b12c5a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
